import pandas as pd
import numpy as np
import os
import glob
import sys

# ================= é…ç½® =================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, 'data', 'daily_csv')
CATALOG_PATH = os.path.join(BASE_DIR, 'master_catalog.csv')

# é˜ˆå€¼è®¾ç½®
CORR_THRESHOLD_STRICT = 0.995 # æé«˜ç›¸å…³æ€§ï¼Œå‡ ä¹è‚¯å®šæ˜¯é‡å¤ï¼Œç›´æ¥æ€
CORR_THRESHOLD_LOOSE = 0.98   # é«˜ç›¸å…³æ€§ï¼Œéœ€è¦æ£€æŸ¥æ˜¯å¦æ˜¯ Smart Beta

# è±å…å…³é”®è¯ (Smart Beta / å› å­ / é£æ ¼)
# å¦‚æœåå­—é‡Œå¸¦è¿™äº›è¯ï¼Œå³ä½¿ç›¸å…³æ€§åœ¨ 0.98-0.995 ä¹‹é—´ï¼Œä¹Ÿè¢«è§†ä¸ºâ€œä¸åŒç­–ç•¥â€ï¼Œäºˆä»¥ä¿ç•™
WHITELIST_KEYWORDS = [
    'VALUE', 'GROWTH', 'QUALITY', 'MOMENTUM', 'LOW VOL', 'MIN VOL', 
    'FACTOR', 'EQUAL WEIGHT', 'DIVIDEND', 'ALPHADEX', 'FUNDAMENTAL'
]

def load_active_universe():
    """
    åªè¯»å– master_catalog ä¸­ is_active=1 çš„èµ„äº§
    è¿”å›: dict {ticker: description} ç”¨äºç™½åå•æ£€æŸ¥
    """
    if not os.path.exists(CATALOG_PATH):
        print("é”™è¯¯: æ‰¾ä¸åˆ° master_catalog.csv")
        sys.exit(1)
        
    df = pd.read_csv(CATALOG_PATH)
    
    # æ ¸å¿ƒé€»è¾‘ï¼šåªå–æ´»è·ƒèµ„äº§
    active_df = df[df['is_active'] == 1].copy()
    
    # æ„å»ºå­—å…¸ {ticker: 'Description String'}
    # æ‹¼åˆ sub_class å’Œ description ä»¥ä¾¿å…¨é¢æ£€æŸ¥å…³é”®è¯
    meta_dict = {}
    for _, row in active_df.iterrows():
        desc = str(row.get('description', '')) + " " + str(row.get('sub_class', '')) + " " + str(row.get('sector_style', ''))
        meta_dict[row['ticker']] = desc.upper()
        
    print(f"ğŸ“‹ ä» Catalog ä¸­è¯»å–åˆ° {len(meta_dict)} ä¸ªæ´»è·ƒèµ„äº§ã€‚")
    return meta_dict

def load_data_for_active(active_tickers_list):
    """
    åªåŠ è½½æ´»è·ƒèµ„äº§çš„ CSV
    """
    print("æ­£åœ¨åŠ è½½æ´»è·ƒèµ„äº§çš„å†å²æ•°æ®...")
    price_dict = {}
    stats = {}
    
    for ticker in active_tickers_list:
        file_path = os.path.join(DATA_DIR, f"{ticker}.csv")
        
        if not os.path.exists(file_path):
            # å¯èƒ½æ˜¯æ–°åŠ çš„è¿˜æ²¡ä¸‹è½½ï¼Œè·³è¿‡
            continue
            
        try:
            df = pd.read_csv(file_path, parse_dates=['date'], index_col='date')
            if df.empty: continue
            
            # ç®€å•çš„åˆ—åå¤„ç†
            df.columns = [c.lower() for c in df.columns]
            col = 'adj_close' if 'adj_close' in df.columns else 'close'
            price_dict[ticker] = df[col]
            
            # ç»Ÿè®¡å±æ€§
            recent = df.tail(60) # æœ€è¿‘ä¸€å­£åº¦çš„æµåŠ¨æ€§
            avg_dollar_vol = 0
            if 'volume' in recent.columns and 'close' in recent.columns:
                avg_dollar_vol = (recent['close'] * recent['volume']).mean()
                
            stats[ticker] = {
                'days': len(df),
                'liquidity': avg_dollar_vol
            }
            
        except Exception as e:
            print(f"Warning: è¯»å– {ticker} å‡ºé”™: {e}")

    # åˆå¹¶
    full_prices = pd.DataFrame(price_dict)
    # è‡³å°‘è¦æœ‰åŠå¹´çš„é‡å æ•°æ®æ‰è®¡ç®—ç›¸å…³æ€§
    full_prices = full_prices.dropna(axis=1, thresh=120)
    
    return full_prices, stats

def is_smart_beta(ticker, meta_dict):
    """æ£€æŸ¥æ˜¯å¦å±äºå› å­/èªæ˜è´å¡”ç­–ç•¥"""
    desc = meta_dict.get(ticker, "")
    for kw in WHITELIST_KEYWORDS:
        if kw in desc:
            return True, kw
    return False, None

def find_duplicates(prices, stats, meta_dict):
    print(f"\næ­£åœ¨è®¡ç®— {len(prices.columns)} åªèµ„äº§çš„ç›¸å…³æ€§çŸ©é˜µ...")
    
    returns = prices.pct_change()
    corr_matrix = returns.corr(min_periods=120)
    
    duplicates = []
    
    cols = corr_matrix.columns
    for i in range(len(cols)):
        for j in range(i + 1, len(cols)):
            t_a = cols[i]
            t_b = cols[j]
            score = corr_matrix.iloc[i, j]
            
            # åªæœ‰ç›¸å…³æ€§å¾ˆé«˜æ‰å¤„ç†
            if score < CORR_THRESHOLD_LOOSE:
                continue
            
            # === æ ¸å¿ƒåˆ¤å†³é€»è¾‘ ===
            
            # 1. æ£€æŸ¥ç™½åå• (Smart Beta)
            is_sb_a, kw_a = is_smart_beta(t_a, meta_dict)
            is_sb_b, kw_b = is_smart_beta(t_b, meta_dict)
            
            # å¦‚æœåŒ…å« Smart Betaï¼Œä¸”ç›¸å…³æ€§æ²¡åˆ° "å˜æ€é«˜" (0.995)ï¼Œåˆ™è±å…
            if (is_sb_a or is_sb_b) and score < CORR_THRESHOLD_STRICT:
                # è¿™é‡Œæˆ‘ä»¬é€‰æ‹©ã€ä¸æŠ¥å‘Šã€‘ï¼Œæˆ–è€…æŠ¥å‘Šä¸ºã€Safe Pairã€‘
                # ä¸ºäº†ä¿æŒ Kill List å¹²å‡€ï¼Œæˆ‘ä»¬ç›´æ¥è·³è¿‡ï¼Œæ„å‘³ç€ç³»ç»Ÿè®¤ä¸ºå®ƒä»¬â€œä¸é‡å¤â€
                continue
            
            # 2. PK é€»è¾‘
            stat_a = stats.get(t_a, {})
            stat_b = stats.get(t_b, {})
            
            liq_a = stat_a.get('liquidity', 0)
            liq_b = stat_b.get('liquidity', 0)
            days_a = stat_a.get('days', 0)
            days_b = stat_b.get('days', 0)
            
            # å†å²é•¿åº¦æƒé‡ (å¦‚æœå·®å¾ˆå¤šå¹´)
            year_diff = abs(days_a - days_b) / 252
            
            if year_diff > 5:
                # å†å²ä¼˜å…ˆ
                if days_a > days_b:
                    winner, loser = t_a, t_b
                    reason = f"å†å²æ›´é•¿ (+{year_diff:.1f}y)"
                else:
                    winner, loser = t_b, t_a
                    reason = f"å†å²æ›´é•¿ (+{year_diff:.1f}y)"
            else:
                # æµåŠ¨æ€§ä¼˜å…ˆ
                if liq_a > liq_b:
                    winner, loser = t_a, t_b
                    ratio = liq_a / (liq_b + 1)
                    reason = f"æµåŠ¨æ€§æ›´å¥½ ({ratio:.1f}x)"
                else:
                    winner, loser = t_b, t_a
                    ratio = liq_b / (liq_a + 1)
                    reason = f"æµåŠ¨æ€§æ›´å¥½ ({ratio:.1f}x)"
            
            duplicates.append({
                'Keep': winner,
                'Drop': loser,
                'Correlation': score,
                'Reason': reason,
                'Type': 'Hard Duplicate' if score >= CORR_THRESHOLD_STRICT else 'Soft Duplicate'
            })

    return pd.DataFrame(duplicates)

def main():
    # 1. è·å–åå•
    meta_dict = load_active_universe()
    active_tickers = list(meta_dict.keys())
    
    if not active_tickers:
        print("æ²¡æœ‰æ´»è·ƒèµ„äº§ã€‚è¯·æ£€æŸ¥ master_catalog.csvã€‚")
        return

    # 2. åŠ è½½æ•°æ®
    prices, stats = load_data_for_active(active_tickers)
    
    # 3. æŸ¥æ‰¾é‡å¤
    result_df = find_duplicates(prices, stats, meta_dict)
    
    if result_df.empty:
        print("\nâœ… èµ„äº§æ± å¾ˆå¹²å‡€ï¼æ²¡æœ‰å‘ç°éœ€ç§»é™¤çš„é‡å¤é¡¹ã€‚")
    else:
        # å»é‡ï¼šåŒä¸€ä¸ª Drop å¯èƒ½å‡ºç°å¤šæ¬¡ï¼Œå–ç›¸å…³æ€§æœ€é«˜çš„é‚£ä¸ªç†ç”±
        result_df = result_df.sort_values('Correlation', ascending=False)
        result_df = result_df.drop_duplicates(subset=['Drop'])
        
        print("\n" + "="*80)
        print(f"ğŸ”ª å»ºè®®ç§»é™¤æ¸…å• (å…± {len(result_df)} ä¸ª)")
        print(f"ç­›é€‰æ ‡å‡†: Active Only | Smart Beta Protected | Strict > {CORR_THRESHOLD_STRICT}")
        print("="*80)
        
        print(result_df[['Keep', 'Drop', 'Correlation', 'Reason']].to_string(index=False))
        
        # ä¿å­˜
        out_path = os.path.join(BASE_DIR, 'duplicates_report.csv')
        result_df.to_csv(out_path, index=False)
        print(f"\næŠ¥å‘Šå·²ä¿å­˜è‡³: {out_path}")
        
        # æ‰“å°æ–¹ä¾¿å¤åˆ¶çš„ Kill List
        drops = result_df['Drop'].tolist()
        print("\n[Action Info] è¯·å» master_catalog.csv å°†ä»¥ä¸‹ Ticker çš„ is_active è®¾ä¸º 0:")
        print(", ".join(drops))

if __name__ == "__main__":
    main()